TRUE * 1
FALSE * 1
knitr::opts_chunk$set(echo = TRUE)
observations <- f + rnorm(length(x), mean = 0, sd = 15)
set.seed(123)
library(ggplot2)
true_relationship <- function(x) { return(6*xˆ3 + 6*xˆ2 - 12*x) }
x <- seq(-3, 2, by = 0.1)
f <- true_relationship(x)
true_relationship <- function(x) { return(6*xˆ3 + 6*xˆ2 - 12*x) }
#set.seed(123)
library(ggplot2)
true_relationship <- function(x) { return(6*xˆ3 + 6*xˆ2 - 12*x) }
x <- seq(-3, 2, by = 0.1)
f <- true_relationship(x)
View(true_relationship)
set.seed(123)
library(ggplot2)
true_relationship <- function(x) {
return(6*x^3 + 6*x^2 - 12*x)
}
x <- seq(-3, 2, by = 0.1)
f <- true_relationship(x)
ggplot() + geom_line(aes(x = x, y = f), color = "black")
knitr::opts_chunk$set(echo = TRUE)
observations <- f + rnorm(length(x), mean = 0, sd = 15)
model1 <- lm(observations ~ poly(x, 1))
predictions1 <- predict(model1, newdata = data.frame(x = x))
model25 <- lm(observations ~ poly(x, 25))
predictions25 <- predict(model25, newdata = data.frame(x = x))
data <- data.frame(x = x,
f = f,
observations = observations,
lm = predictions1,
pm = predictions25)
ggplot(data, aes(x = x)) +
geom_line(aes(y = f), color = "black") +
geom_point(aes(y = observations), color = "blue", shape = 1) +
geom_line(aes(y = lm), color = "red", linetype = "solid") +
geom_line(aes(y = pm), color = "orange", linetype = "solid") +
geom_point(aes(x = 1, y = data[x == 1, "lm"]), color = "red", shape=2) +
geom_point(aes(x = 1, y = data[x == 1, "pm"]), color = "orange", shape=2)
observations_new <- f + rnorm(length(x), mean = 0, sd = 15)
model1 <- lm(observations_new ~ poly(x, 1))
predictions1 <- predict(model1, newdata = data.frame(x = x))
model25 <- lm(observations_new ~ poly(x, 25))
predictions25 <- predict(model25, newdata = data.frame(x = x))
data <- data.frame(x = x,
f = f,
observations = observations_new,
lm = predictions1,
pm = predictions25)
ggplot(data, aes(x = x)) +
geom_line(aes(y = f), color = "black") +
geom_point(aes(y = observations_new), color = "blue", shape = 1) +
geom_line(aes(y = lm), color = "red", linetype = "solid") +
geom_line(aes(y = pm), color = "orange", linetype = "solid") +
geom_point(aes(x = 1, y = data[x == 1, "lm"]), color = "red", shape=2) +
geom_point(aes(x = 1, y = data[x == 1, "pm"]), color = "orange", shape=2)
results1 <- data.frame(x = 1, f_pred = 0)
for (i in 1:500) {
x <- seq(-3, 2, by = 0.1)
f <- true_relationship(x)
temp_observations <- f + rnorm(length(x), mean=0, sd=15)
model1 <- lm(temp_observations ~ poly(x, 1))
results1[i, 1] <- 1
results1[i, 2] <- predict(model1, newdata = data.frame(x=1))
}
ggplot() +
geom_line(data = data, aes(x = x, y = f), color = "black") +
geom_point(data = results1, aes(x = x, y = f_pred), color="red", shape=2)
results20 <- data.frame(x = 1, f_pred = 0)
for (i in 1:500) {
x <- seq(-3, 2, by = 0.1)
f <- true_relationship(x)
temp_observations <- f + rnorm(length(x), mean=0, sd=15)
model20 <- lm(temp_observations ~ poly(x, 20))
results20[i, 1] <- 1
results20[i, 2] <- predict(model20, newdata = data.frame(x=1))
}
ggplot() +
geom_line(data = data, aes(x = x, y = f), color = "black") +
geom_point(data = results20, aes(x = x, y = f_pred), color="orange", shape=2)
models <- vector("list", 25)
for (degree in 1:25) {
model <- lm(observations ~ poly(x, degree))
models[[degree]] <- model
}
results <- data.frame(degree = 1:25, rmse = 0)
for (degree in 1:25) {
predictions <- predict(models[[degree]], newdata = data.frame(x=x))
results[results$degree==degree, "rmse"] <-
sqrt((1/length(predictions))*sum((predictions-observations)ˆ2))
knitr::opts_chunk$set(echo = TRUE)
models <- vector("list", 25)
for (degree in 1:25) {
model <- lm(observations ~ poly(x, degree))
models[[degree]] <- model
}
results <- data.frame(degree = 1:25, rmse = 0)
for (degree in 1:25) {
predictions <- predict(models[[degree]], newdata = data.frame(x=x))
results[results$degree==degree, "rmse"] <-
sqrt((1/length(predictions))*sum((predictions-observations)^2))
}
ggplot() +
geom_line(data = results, aes(x = degree, y = rmse), color = "black")
results <- data.frame(degree = 1:25, rmse = 0)
for (degree in 1:25) {
predictions <- predict(models[[degree]], newdata = data.frame(x=x))
results[results$degree==degree, "rmse"] <-
sqrt((1/length(predictions))*sum((predictions-observations_new)^2))
}
ggplot() +
geom_line(data = results, aes(x = degree, y = rmse), color = "black")
View(results20)
View(models)
knitr::opts_chunk$set(echo = TRUE)
model <- lm(observations ~ poly(x, 4))
predictions=predict(model, newdata = data.frame(x=x))
data = data.frame(x=x, f=f, predictions=predictions)
ggplot(data, aes(x=x)) +
geom_line(aes(y = f), color = "black") +
geom_line(aes(y = predictions), color = "red", linetype="solid")
library(keras)
library(reticulate)
library(tensorflow)
tensorflow::tf_config()
use_virtualenv("my_tf_workspace")
library(keras)
library(reticulate)
library(tensorflow)
use_virtualenv("my_tf_workspace")
tensorflow::tf_config()
setwd("C:/Users/janna/Documents/Merrimack MSDS/DSE6211/Week 8")
library(dplyr)
library(caret)
library(NbClust)
########################### Data Pre-processing ################################
data <- read.csv("lab_8_data/lab_8_data.csv")
training_ind <- createDataPartition(data$lodgepole_pine,
p = 0.75,
list = F,
times = 1)
training_set <- data[training_ind, ]
test_set <- data[-training_ind, ]
top_20_soil_types <- training_set %>%
group_by(soil_type) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
select(soil_type) %>%
top_n(20)
training_set$soil_type <- ifelse(training_set$soil_type %in% top_20_soil_types$soil_type,
training_set$soil_type,
"other")
training_set$wilderness_area <- factor(training_set$wilderness_area)
training_set$soil_type <- factor(training_set$soil_type)
onehot_encoder <- dummyVars(~ wilderness_area + soil_type,
training_set[, c("wilderness_area", "soil_type")],
levelsOnly = T,
fullRank = T)
onehot_enc_training <- predict(onehot_encoder,
training_set[, c("wilderness_area", "soil_type")])
training_set <- cbind(training_set, onehot_enc_training)
test_set$soil_type <- ifelse(test_set$soil_type %in% top_20_soil_types$soil_type,
test_set$soil_type,
"other")
test_set$wilderness_area <- factor(test_set$wilderness_area)
test_set$soil_type <- factor(test_set$soil_type)
onehot_enc_test <- predict(onehot_encoder, test_set[, c("wilderness_area", "soil_type")])
test_set <- cbind(test_set, onehot_enc_test)
test_set[, -c(11:13)] <- scale(test_set[, -c(11:13)],
center = apply(training_set[, -c(11:13)], 2, mean),
scale = apply(training_set[, -c(11:13)], 2, sd))
training_set[, -c(11:13)] <- scale(training_set[, -c(11:13)])
training_features <- array(data = unlist(training_set[, -c(11:13)]),
dim = c(nrow(training_set), 33))
training_labels <- array(data = unlist(training_set[, 13]),
dim = c(nrow(training_set)))
test_features <- array(data = unlist(training_set[, -c(11:13)]),
dim = c(nrow(test_set), 33))
test_labels <- array(data = unlist(training_set[, 13]),
dim = c(nrow(test_set)))
######################### K-mean clustering ####################################
set.seed(123)
nc <- NbClust(training_features[sample(nrow(training_features), 1000), c(4, 6, 10)],
min.nc = 2, max.nc = 10, method = "kmeans")
km_clusters <- kmeans(training_features[, c(4, 6, 10)], centers = 4)
cluster_number <- data.frame(cluster_number = km_clusters$cluster)
training_features <- cbind(training_features, cluster_number)
head(training_features)
View(km_clusters)
print(km_clusters$size)
print(km$clusters$centers)
print(km_clusters$centers)
km_clusters <- kmeans(training_features[, c(4, 6, 10)], centers = 3)
cluster_number <- data.frame(cluster_number = km_clusters$cluster)
training_features <- cbind(training_features, cluster_number)
head(training_features)
print(km_clusters$size)
print(km_clusters$centers)
aggregate(training_features[, 4], by=list(training_features$cluster_number), FUN=mean)
?paste()
for (x in c(4,6,10)) {
f_name <-  colnames(training_features)[x]
f_means <-  aggregate(training_features[, x],
by=list(training_features$cluster_number),
FUN=mean)
paste(f_name, "mean equals", f_means)
}
for (x in c(4,6,10)) {
f_name <-  colnames(training_features)[x]
f_means <-  aggregate(training_features[, x],
by=list(training_features$cluster_number),
FUN=mean)
print(paste(f_name, "mean equals", f_means))
}
for (x in c(4,6,10)) {
f_name <-  colnames(training_features)[x]
f_means <-  aggregate(training_features[, x],
by=list(training_features$cluster_number),
FUN=mean)
print(f_means)
}
for (x in c(4,6,10)) {
f_name <-  colnames(training_features)[x]
f_means <-  aggregate(training_features[, x],
by=list(training_features$cluster_number),
FUN=mean)
print(paste("Means for ", f_name))
print(f_means)
}
View(training_features)
install.packages("clue")
predictions <- cl_predict(km_clusters, newdata = test_features[, c(4,6,10)])
library(clue)
predictions <- cl_predict(km_clusters, newdata = test_features[, c(4,6,10)])
test_features <- cbind(test_features, predictions)
head(test_features)
